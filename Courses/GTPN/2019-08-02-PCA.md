## Dimensionality Reduction
#### Byron Yu

### Motivation
- Neurons form networks, so each neuron cannot act independently
- Fewer degrees of freedom than the number of neurons at play
- Spikes -> Noisy time series -> denoised time series -> low-D time series
- Reasons to use dimensionality reduction
  1. Single-trial analyses of neural population activity
  2. Hypothesis about population activity structure


### Dimensionality Reduction Methods
1. Principal Components Analysis (PCA)
  - Good for trial-averaged analyses; no concept of "noise"
  - Not good for single trials
2. Factor Analysis (FA)
  - Good for single-trial; no temporal smoothing
  - Tries to identify activity shared between neurons
  - "noise" here is highly related to Poisson noise 
3. Gaussian-process factor analysis (GPFA)
  - Good for single-trial analysis; has temporal smoothing
  - Starts with factor analysis, uses gaussian-process for smoothing
  - Finds dimensions of variance that vary smoothly over time
4. Latent dynamical systems (e.g. LDS, LFADS) 
  - Use if want to incorporate dynamical rules governing time-evolution of neural activity
5. Non-linear methods (e.g. Isomap, LLE)
  - Generally not recommended; typically don't deal well with noisy data
6. Supervised methods (e.g. LDA, dPCA)
  - Good for identifying dimensions that represent stimulus, behavior, and/or time

